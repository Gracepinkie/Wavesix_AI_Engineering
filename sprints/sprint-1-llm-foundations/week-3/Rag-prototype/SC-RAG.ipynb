{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff3fdefa-6ecd-45bc-b9ac-c957add8c92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a Mini-RAG (Retrieval-Augmented Generation) with LlamaIndex and OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a94aa67-75c6-4651-b2d4-8c8f46f11640",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index-llms-openai in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (0.3.38)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.17 in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from llama-index-llms-openai) (0.12.35)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.66.3 in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from llama-index-llms-openai) (1.78.1)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (3.11.18)\n",
      "Requirement already satisfied: aiosqlite in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (0.21.0)\n",
      "Requirement already satisfied: banks<3,>=2.0.0 in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (2.1.2)\n",
      "Requirement already satisfied: dataclasses-json in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (1.0.8)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (2025.3.2)\n",
      "Requirement already satisfied: httpx in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (3.9.1)\n",
      "Requirement already satisfied: numpy in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (2.2.5)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (11.2.1)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (2.11.4)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (2.32.3)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (2.0.41)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (9.1.2)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (4.13.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (1.17.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from openai<2.0.0,>=1.66.3->llama-index-llms-openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from openai<2.0.0,>=1.66.3->llama-index-llms-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from openai<2.0.0,>=1.66.3->llama-index-llms-openai) (0.9.0)\n",
      "Requirement already satisfied: sniffio in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from openai<2.0.0,>=1.66.3->llama-index-llms-openai) (1.3.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (1.20.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.66.3->llama-index-llms-openai) (3.10)\n",
      "Requirement already satisfied: griffe in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (1.7.3)\n",
      "Requirement already satisfied: jinja2 in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (3.1.6)\n",
      "Requirement already satisfied: platformdirs in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (4.3.8)\n",
      "Requirement already satisfied: certifi in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (0.16.0)\n",
      "Requirement already satisfied: click in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (8.2.0)\n",
      "Requirement already satisfied: joblib in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (1.5.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (2.4.0)\n",
      "Requirement already satisfied: greenlet>=1 in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (3.2.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (3.26.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (25.0)\n",
      "Requirement already satisfied: colorama>=0.4 in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from griffe->banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/sinethembazulu/Documents/Wavesix-AI-Engineering/venv/lib/python3.13/site-packages (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.17->llama-index-llms-openai) (3.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index-llms-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2432456d-885b-4cac-946a-0965cf72923f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/homebrew/Cellar/jupyterlab/4.4.1_1/libexec/lib/python3.13/site-packages (25.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7543a2e-a486-4e48-b459-d1db29015669",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd1d7966-8324-4774-978a-4cf3e17bffa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12.35\n"
     ]
    }
   ],
   "source": [
    "import importlib.metadata\n",
    "print(importlib.metadata.version(\"llama-index\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e967e66d-4011-40a6-8bf8-8e8f0d3ac95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import (\n",
    "    SimpleDirectoryReader,\n",
    "    VectorStoreIndex,\n",
    "    Settings,\n",
    ")\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.response_synthesizers import CompactAndRefine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6de096cf-5a05-4878-896a-b45facd75c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set global configuration using Settings\n",
    "Settings.llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")\n",
    "Settings.node_parser = SentenceSplitter(chunk_size=512, chunk_overlap=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f007c095-61bd-4ebd-a632-a31f9db62333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📄 Number of documents loaded: 432\n",
      "\n",
      "🔍 Document Preview:\n",
      "\n",
      "Historical Dictionary\n",
      "of the Zulu Wars\n",
      "John Laband\n",
      "Historical Dictionaries of War, \n",
      "Revolution, and Civil Unrest, No. 37\n",
      "The Scarecrow Press, Inc.\n",
      "Lanham, Maryland • Toronto • Oxford\n",
      "2009\n"
     ]
    }
   ],
   "source": [
    "# Load files from the \"data\" folder\n",
    "documents = SimpleDirectoryReader(\"data\").load_data()\n",
    "\n",
    "# Automatically uses the splitter defined in Settings\n",
    "# Splits into \"nodes\" (chunks of documents)\n",
    "# Check how many documents were loaded\n",
    "print(f\"\\n📄 Number of documents loaded: {len(documents)}\")\n",
    "\n",
    "# Preview the first 500 characters of the first document\n",
    "if documents:\n",
    "    print(\"\\n🔍 Document Preview:\\n\")\n",
    "    print(documents[0].text[:200])\n",
    "else:\n",
    "    print(\"⚠️ No documents loaded. Check file format and content.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "274546cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response:\n",
      " The document is about the Zulu Kingdom.\n"
     ]
    }
   ],
   "source": [
    "# Build the index from chunked nodes \n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "\n",
    "# Create a query engine\n",
    "query_engine = index.as_query_engine()\n",
    "\n",
    "# test query\n",
    "response = query_engine.query(\"What is the document about?\")\n",
    "print(\"\\nResponse:\\n\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e03520ac-5d10-4b8e-b36f-1721701c85b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Chunk 1 ---\n",
      "Historical Dictionary\n",
      "of the Zulu Wars\n",
      "John Laband\n",
      "Historical Dictionaries of War, \n",
      "Revolution, and Civil Unrest, No. 37\n",
      "The Scarecrow Press, Inc.\n",
      "Lanham, Maryland • Toronto • Oxford\n",
      "2009\n",
      "\n",
      "--- Chunk 2 ---\n",
      "vii\n",
      "If you like your wars nice and neat, one side against the other, or just the \n",
      "“good guys” beating the “bad guys,” this is not the book for you. In its \n",
      "simplest form, the Zulu Wars can be regarded as a three-way struggle \n",
      "between the Zulus, the Boers, and the British, in various combinations \n",
      "an\n",
      "\n",
      "--- Chunk 3 ---\n",
      "about the Zulu Wars extensively, including several books and numer-\n",
      "ous articles. He has also shown increasing interest in the Zulu people \n",
      "themselves, having coedited Zulu Identities: Being Zulu, Past and \n",
      "Present. This Historical Dictionary of the Zulu Wars thus benefits from \n",
      "Professor Laband’s c\n",
      "\n",
      "--- Chunk 4 ---\n",
      "ix\n",
      "Acknowledgments\n",
      "A historical dictionary covering 50 years of conflict in 19th-century Zu-\n",
      "luland and its neighboring states must owe an enormous debt to scholars \n",
      "who have researched not only the Zulu kingdom but also colonial Natal \n",
      "and the Cape, the Boer republics, the Ndebele, Tsonga, Swazi, P\n",
      "\n",
      "--- Chunk 5 ---\n",
      "xi\n",
      "Reader’s Notes\n",
      "There is no settled terminology for either the various conflicts in Zulu-\n",
      "land between 1838 and 1888 or the progressive dismemberments of the \n",
      "Zulu kingdom. In the interests of consistency, concision, and clarity, \n",
      "variant terms have been eliminated from the text. This has meant de\n",
      "\n",
      "--- Chunk 6 ---\n",
      "Entries in the dictionary that include a number, \n",
      "such as that of a regiment, battalion, or battery, are alphabetized under \n",
      "the name of the military formation, for example “Natal Native Contin-\n",
      "gent, 1st Battalion” or “Royal Artillery, H Battery, 4th Brigade.” The \n",
      "same goes for field formations, s\n"
     ]
    }
   ],
   "source": [
    "# Manually split into nodes using the parser\n",
    "nodes = Settings.node_parser.get_nodes_from_documents(documents)\n",
    "\n",
    "# Preview a few chunks\n",
    "for i, node in enumerate(nodes[:6]):\n",
    "    print(f\"\\n--- Chunk {i+1} ---\")\n",
    "    print(node.text[:300])  # Show first 300 characters of the chunk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eec0fa15-1cf2-45bb-84cf-f95e86891d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "098a996b-cc41-4b7b-8086-b65e0b5dad79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use top-3 most similar chunks\n",
    "retriever = VectorIndexRetriever(index=index, similarity_top_k=3)\n",
    "\n",
    "synthesizer = CompactAndRefine()\n",
    "# Put everything together\n",
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever=retriever,\n",
    "    response_synthesizer=synthesizer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40da777d-aacc-451c-8f52-9b0d57e159fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Zulu kingdom wars encompassed a series of conflicts between the Zulu kingdom and advancing colonial forces, starting with the Voortrekker invasion in 1838 and ending in 1888 with the failure of resistance to newly imposed British rule. These wars excluded earlier Zulu campaigns against neighboring African polities and the participation of Zulu people as British subjects in the Anglo-Boer War of 1899–1902. The Zulu Wars also involved civil wars within the Zulu kingdom triggered by destabilization, making it vulnerable to partition by colonial neighbors.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query( \"tell me about the Zulu kingdom wars\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5700d090-e1d1-4738-a4e8-e5c180b8c152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔖 Source 1:\n",
      "ZULU KINGDOM. The Zulu kingdom lasted only a little over six \n",
      "decades in the 19th century before being overthrown in war, broken \n",
      "into pieces, consigned to civil war, and eventually annexed piecemeal \n",
      "\n",
      "🔖 Source 2:\n",
      "xli\n",
      "Introduction\n",
      "The term “Zulu Wars” is very imprecise, there being no single, gen-\n",
      "erally accepted understanding of what it encompasses. Most often it \n",
      "is sloppily applied to the Anglo-Zulu War of 1\n",
      "\n",
      "🔖 Source 3:\n",
      "Only \n",
      "about 2,000 of the iziGqoza warriors escaped to Natal. The uSuthu \n",
      "casualties are unknown, though their right horn suffered heavily \n",
      "from gunfire. The battle decided the Zulu succession in Cetsh\n"
     ]
    }
   ],
   "source": [
    "for i, node in enumerate(response.source_nodes):\n",
    "    print(f\"\\n🔖 Source {i+1}:\\n{node.node.get_content()[:200]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281a8996-06a7-44d7-b087-120f43247fc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
